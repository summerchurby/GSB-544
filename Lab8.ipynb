{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One: Binary Classification\n",
    "\n",
    "Create a dataset that is limited only to the Sativa and Indica type cannabis strains.\n",
    "\n",
    "This section asks you to create a final best model for each of the four new model types studied this week: LDA, QDA, SVC, and SVM. For SVM, you may limit yourself to only the polynomial kernel.\n",
    "\n",
    "For each, you should:\n",
    "\n",
    "* Choose a metric you will use to select your model, and briefly justify your choice. (Hint: There is no specific target category here, so this should not be a metric that only prioritizes one category.)\n",
    "\n",
    "* Find the best model for predicting the Type variable. Don’t forget to tune any hyperparameters.\n",
    "\n",
    "* Report the (cross-validated!) metric.\n",
    "\n",
    "* Fit the final model.\n",
    "\n",
    "* Output a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cannabis = pd.read_csv(r\"C:\\Users\\achur\\OneDrive\\Desktop\\School\\CP Fall 2024\\544\\cannabis_full.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Results\n",
      "Best Hyperparameters: {}\n",
      "Cross-validated accuracy: 0.8548469212246301\n",
      "Confusion Matrix:\n",
      " [[125   7]\n",
      " [ 23  59]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      indica       0.84      0.95      0.89       132\n",
      "      sativa       0.89      0.72      0.80        82\n",
      "\n",
      "    accuracy                           0.86       214\n",
      "   macro avg       0.87      0.83      0.85       214\n",
      "weighted avg       0.86      0.86      0.86       214\n",
      "\n",
      "LDA Results\n",
      "Best Hyperparameters: {}\n",
      "Cross-validated accuracy: 0.8548469212246301\n",
      "Confusion Matrix:\n",
      " [[125   7]\n",
      " [ 23  59]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      indica       0.84      0.95      0.89       132\n",
      "      sativa       0.89      0.72      0.80        82\n",
      "\n",
      "    accuracy                           0.86       214\n",
      "   macro avg       0.87      0.83      0.85       214\n",
      "weighted avg       0.86      0.86      0.86       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# filter for sativa and indica\n",
    "filtered_cannabis = cannabis[cannabis[\"Type\"].isin([\"sativa\", \"indica\"])]\n",
    "filtered_cannabis = filtered_cannabis.dropna()\n",
    "\n",
    "# encode to have type as numeric values\n",
    "le = LabelEncoder()\n",
    "filtered_cannabis[\"Type_encoded\"] = le.fit_transform(filtered_cannabis[\"Type\"])\n",
    "\n",
    "# variables\n",
    "X = filtered_cannabis.drop(columns=[\"Strain\", \"Type\", \"Type_encoded\", \"Effects\", \"Flavor\"])\n",
    "y = filtered_cannabis[\"Type_encoded\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1, stratify = y)\n",
    "\n",
    "# pipeline to drop missing values\n",
    "preprocessor = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# function for models\n",
    "def evaluate_model(model, param_grid, X_train, y_train, X_test, y_test):\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", model)\n",
    "    ])\n",
    "    # grid search\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    predictions = best_model.predict(X_test)\n",
    "    conf_matrix = confusion_matrix(y_test, predictions)\n",
    "    report = classification_report(y_test, predictions, target_names= le.classes_)\n",
    "    return grid_search.best_params_, grid_search.best_score_, conf_matrix, report\n",
    "\n",
    "# LDA model\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "lda_param_grid = {}\n",
    "lda_results = evaluate_model(lda_model, lda_param_grid, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"LDA Results\")\n",
    "print(\"Best Hyperparameters:\", lda_results[0])\n",
    "print(\"Cross-validated accuracy:\", lda_results[1])\n",
    "print(\"Confusion Matrix:\\n\", lda_results[2])\n",
    "print(\"Classification Report:\\n\", lda_results[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA Results\n",
      "Best Hyperparameters: {}\n",
      "Cross-validated accuracy: 0.4859029927760578\n",
      "Confusion Matrix:\n",
      " [[ 10 122]\n",
      " [  5  77]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      indica       0.67      0.08      0.14       132\n",
      "      sativa       0.39      0.94      0.55        82\n",
      "\n",
      "    accuracy                           0.41       214\n",
      "   macro avg       0.53      0.51      0.34       214\n",
      "weighted avg       0.56      0.41      0.29       214\n",
      "\n",
      "QDA Results\n",
      "Best Hyperparameters: {}\n",
      "Cross-validated accuracy: 0.4859029927760578\n",
      "Confusion Matrix:\n",
      " [[ 10 122]\n",
      " [  5  77]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      indica       0.67      0.08      0.14       132\n",
      "      sativa       0.39      0.94      0.55        82\n",
      "\n",
      "    accuracy                           0.41       214\n",
      "   macro avg       0.53      0.51      0.34       214\n",
      "weighted avg       0.56      0.41      0.29       214\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achur\\Downloads\\python\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "# qda model\n",
    "\n",
    "qda_model = QuadraticDiscriminantAnalysis()\n",
    "qda_param_grid = {}\n",
    "qda_results = evaluate_model(qda_model, qda_param_grid, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"QDA Results\")\n",
    "print(\"Best Hyperparameters:\", qda_results[0])\n",
    "print(\"Cross-validated accuracy:\", qda_results[1])\n",
    "print(\"Confusion Matrix:\\n\", qda_results[2])\n",
    "print(\"Classification Report:\\n\", qda_results[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Results\n",
      "Best Hyperparameters: {'classifier__C': 0.1, 'classifier__kernel': 'linear'}\n",
      "Cross-validated accuracy: 0.8548675610595116\n",
      "Confusion Matrix:\n",
      " [[122  10]\n",
      " [ 18  64]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      indica       0.87      0.92      0.90       132\n",
      "      sativa       0.86      0.78      0.82        82\n",
      "\n",
      "    accuracy                           0.87       214\n",
      "   macro avg       0.87      0.85      0.86       214\n",
      "weighted avg       0.87      0.87      0.87       214\n",
      "\n",
      "SVC Results\n",
      "Best Hyperparameters: {'classifier__C': 0.1, 'classifier__kernel': 'linear'}\n",
      "Cross-validated accuracy: 0.8548675610595116\n",
      "Confusion Matrix:\n",
      " [[122  10]\n",
      " [ 18  64]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      indica       0.87      0.92      0.90       132\n",
      "      sativa       0.86      0.78      0.82        82\n",
      "\n",
      "    accuracy                           0.87       214\n",
      "   macro avg       0.87      0.85      0.86       214\n",
      "weighted avg       0.87      0.87      0.87       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# svc model\n",
    "\n",
    "svc_model = SVC(probability=True, random_state=1)\n",
    "svc_param_grid = {\n",
    "    \"classifier__C\": [0.1, 1, 10],\n",
    "    \"classifier__kernel\": [\"linear\", \"rbf\",]\n",
    "}\n",
    "svc_results = evaluate_model(svc_model, svc_param_grid, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"SVC Results\")\n",
    "print(\"Best Hyperparameters:\", svc_results[0])\n",
    "print(\"Cross-validated accuracy:\", svc_results[1])\n",
    "print(\"Confusion Matrix:\\n\", svc_results[2])\n",
    "print(\"Classification Report:\\n\", svc_results[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with Polynomial Kernel Results\n",
      "Best Hyperparameters: {'classifier__C': 0.1, 'classifier__coef0': 1, 'classifier__degree': 4}\n",
      "Cross-validated accuracy: 0.8618507051943585\n",
      "Confusion Matrix:\n",
      " [[124   8]\n",
      " [ 21  61]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      indica       0.86      0.94      0.90       132\n",
      "      sativa       0.88      0.74      0.81        82\n",
      "\n",
      "    accuracy                           0.86       214\n",
      "   macro avg       0.87      0.84      0.85       214\n",
      "weighted avg       0.87      0.86      0.86       214\n",
      "\n",
      "SVM with Polynomial Kernel Results\n",
      "Best Hyperparameters: {'classifier__C': 0.1, 'classifier__coef0': 1, 'classifier__degree': 4}\n",
      "Cross-validated accuracy: 0.8618507051943585\n",
      "Confusion Matrix:\n",
      " [[124   8]\n",
      " [ 21  61]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      indica       0.86      0.94      0.90       132\n",
      "      sativa       0.88      0.74      0.81        82\n",
      "\n",
      "    accuracy                           0.86       214\n",
      "   macro avg       0.87      0.84      0.85       214\n",
      "weighted avg       0.87      0.86      0.86       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# svm model\n",
    "\n",
    "svm_model = SVC(kernel='poly', probability=True, random_state=42)\n",
    "svm_param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__degree': [2, 3, 4],\n",
    "    'classifier__coef0': [0, 1],\n",
    "}\n",
    "svm_results = evaluate_model(svm_model, svm_param_grid, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"SVM with Polynomial Kernel Results\")\n",
    "print(\"Best Hyperparameters:\", svm_results[0])\n",
    "print(\"Cross-validated accuracy:\", svm_results[1])\n",
    "print(\"Confusion Matrix:\\n\", svm_results[2])\n",
    "print(\"Classification Report:\\n\", svm_results[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two: Natural Multiclass\n",
    "Now use the full dataset, including the Hybrid strains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Fit a decision tree, plot the final fit, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Repeat the analyses from Part One for LDA, QDA, and KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: Were your metrics better or worse than in Part One? Why? Which categories were most likely to get mixed up, according to the confusion matrices? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Three: Multiclass from Binary \n",
    "Consider two models designed for binary classification: SVC and Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Fit and report metrics for OvR versions of the models. That is, for each of the two model types, create three models:\n",
    "* Indica vs. Not Indica\n",
    "\n",
    "* Sativa vs. Not Sativa\n",
    "\n",
    "* Hybrid vs. Not Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Which of the six models did the best job distinguishing the target category from the rest? Which did the worst? Does this make intuitive sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: Fit and report metrics for OvO versions of the models. That is, for each of the two model types, create three models:\n",
    "\n",
    "* Indica vs. Sativa\n",
    "\n",
    "* Indica vs. Hybrid\n",
    "\n",
    "* Hybrid vs. Sativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: Which of the six models did the best job distinguishing at differentiating the two groups? Which did the worst? Does this make intuitive sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5: Suppose you had simply input the full data, with three classes, into the LogisticRegression function. Would this have automatically taken an “OvO” approach or an “OvR” approach? What about for SVC?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
