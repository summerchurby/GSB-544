{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA 7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames = pd.read_csv(r\"C:\\Users\\achur\\OneDrive\\Desktop\\School\\CP Fall 2024\\544\\AmesHousing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider four possible models for predicting house prices:\n",
    "\n",
    "1. Using only the size and number of rooms.\n",
    "2. Using size, number of rooms, and building type.\n",
    "3. Using size and building type, and their interaction.\n",
    "4. Using a 5-degree polynomial on size, a 5-degree polynomial on number of rooms, and also building type.\n",
    "5. Set up a pipeline for each of these four models.\n",
    "\n",
    "Then, get predictions on the test set for each of your pipelines, and compute the root mean squared error. Which model performed best?\n",
    "\n",
    "Note: You should only use the function train_test_split() one time in your code; that is, we should be predicting on the same test set for all three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achur\\Downloads\\python\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\achur\\Downloads\\python\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\achur\\Downloads\\python\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\achur\\Downloads\\python\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Scores: {'model1': 51020.35394090045, 'model2': 49737.74135592328, 'model3': 49300.879028881696, 'model4': 62723.925214953146}\n",
      "Best Model: model3\n",
      "RMSE Scores: {'model1': 51020.35394090045, 'model2': 49737.74135592328, 'model3': 49300.879028881696, 'model4': 62723.925214953146}\n",
      "Best Model: model3\n"
     ]
    }
   ],
   "source": [
    "# variables\n",
    "X = ames[[\"Gr Liv Area\", \"TotRms AbvGrd\", \"Bldg Type\"]]\n",
    "y = ames[\"SalePrice\"]\n",
    "\n",
    "# training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "# preprocessing\n",
    "numeric_features = [\"Gr Liv Area\", \"TotRms AbvGrd\"]\n",
    "categorical_features = [\"Bldg Type\"]\n",
    "basic_preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), numeric_features),\n",
    "    (\"cat\", OneHotEncoder(drop = \"first\"), categorical_features)\n",
    "], remainder=\"drop\")\n",
    "\n",
    "# model 1: size and number of rooms\n",
    "model1 = Pipeline([\n",
    "    (\"preprocessor\", ColumnTransformer([\n",
    "        (\"num\", StandardScaler(), numeric_features)\n",
    "    ], remainder=\"drop\")),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "# model 2: size, number of rooms, and building type\n",
    "model2 = Pipeline([\n",
    "    (\"preprocessor\", basic_preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "# model 3: size, building type, and interactions\n",
    "model3 = Pipeline([\n",
    "    (\"preprocessor\", basic_preprocessor),\n",
    "    (\"interaction\", PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "# model 4: polynomial 5 on size and rooms and building type\n",
    "model4 = Pipeline([\n",
    "    (\"preprocessor\", basic_preprocessor),\n",
    "    (\"poly_features\", PolynomialFeatures(degree=5, include_bias=False)),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "# dictionary\n",
    "pipelines = {\n",
    "    \"model1\": model1,\n",
    "    \"model2\": model2,\n",
    "    \"model3\": model3,\n",
    "    \"model4\": model4\n",
    "}\n",
    "\n",
    "# performance metrics\n",
    "rmse_scores = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    rmse_scores[name] = mean_squared_error(y_test, y_pred, squared = False)\n",
    "\n",
    "# best model \n",
    "bestmodel = min(rmse_scores, key = rmse_scores.get)\n",
    "print(f\"RMSE Scores: {rmse_scores}\")\n",
    "print(f\"Best Model: {bestmodel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again consider four modeling options for house price:\n",
    "\n",
    "Using only the size and number of rooms.\n",
    "Using size, number of rooms, and building type.\n",
    "Using size and building type, and their interaction.\n",
    "Using a 5-degree polynomial on size, a 5-degree polynomial on number of rooms, and also building type.\n",
    "Use cross_val_score with the pipelines you made earlier to find the cross-validated root mean squared error for each model.\n",
    "\n",
    "Which do you prefer? Does this agree with your conclusion from earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated RMSE Scores: {'model1': 56663.06248423473, 'model2': 54753.33632743881, 'model3': 53687.70850488586, 'model4': 205990.54039306747}\n",
      "Best Model by Cross-Validation RMSE: model3\n",
      "Cross-validated RMSE Scores: {'model1': 56663.06248423473, 'model2': 54753.33632743881, 'model3': 53687.70850488586, 'model4': 205990.54039306747}\n",
      "Best Model by Cross-Validation RMSE: model3\n"
     ]
    }
   ],
   "source": [
    "cv_rmse_scores = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv = 5, scoring = 'neg_root_mean_squared_error')\n",
    "    cv_rmse_scores[name] = -np.mean(scores)\n",
    "\n",
    "print(f\"Cross-validated RMSE Scores: {cv_rmse_scores}\")\n",
    "bestmodel = min(cv_rmse_scores, key = cv_rmse_scores.get)\n",
    "print(f\"Best Model by Cross-Validation RMSE: {bestmodel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider one hundred modeling options for house price:\n",
    "\n",
    "House size, trying degrees 1 through 10\n",
    "Number of rooms, trying degrees 1 through 10\n",
    "Building Type\n",
    "Hint: The dictionary of possible values that you make to give to GridSearchCV will have two elements instead of one.\n",
    "\n",
    "Q1: Which model performed the best?\n",
    "\n",
    "Q2: What downsides do you see of trying all possible model options? How might you go about choosing a smaller number of tuning values to try?"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Degrees: (3, 1)\n",
      "Best Cross-Validated RMSE: 52781.98411787206\n",
      "Best Degrees: (3, 1)\n",
      "Best Cross-Validated RMSE: 52781.98411787206\n"
     ]
    }
   ],
=======
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
>>>>>>> 4f861df75a8407e167855210ff45af54ad5f3431
   "source": [
    "# variables\n",
    "X = ames[[\"Gr Liv Area\", \"TotRms AbvGrd\", \"Bldg Type\"]]\n",
    "y = ames[\"SalePrice\"]\n",
    "\n",
<<<<<<< HEAD
    "preprocessor = ColumnTransformer([\n",
    "    (\"poly_size\", PolynomialFeatures(include_bias=False), [\"Gr Liv Area\"]),\n",
    "    (\"poly_rooms\", PolynomialFeatures(include_bias=False), [\"TotRms AbvGrd\"]),\n",
    "    (\"cat\", OneHotEncoder(drop=\"first\"), [\"Bldg Type\"]),\n",
    "    (\"scale\", StandardScaler(), [\"Gr Liv Area\", \"TotRms AbvGrd\"])  # Scale numeric features\n",
    "])\n",
    "\n",
    "# pipeline \n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "# parameter grid\n",
    "param_grid = {\n",
    "    \"preprocessor__poly_size__degree\": range(1, 11),\n",
    "    \"preprocessor__poly_rooms__degree\": range(1, 11)\n",
    "}\n",
    "\n",
    "# grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=\"neg_root_mean_squared_error\", n_jobs=-1)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# paramters and score\n",
    "best_degrees = (grid_search.best_params_[\"preprocessor__poly_size__degree\"], grid_search.best_params_[\"preprocessor__poly_rooms__degree\"])\n",
    "best_rmse = -grid_search.best_score_\n",
    "\n",
    "print(f\"Best Degrees: {best_degrees}\")\n",
=======
    "# preprocess\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), [\"Gr Liv Area\", \"TotRms AbvGrd\"]),\n",
    "    (\"cat\", OneHotEncoder(drop = \"first\"), [\"Bldg Type\"])\n",
    "])\n",
    "\n",
    "# pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"poly_features\", PolynomialFeatures()),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "# degrees 1-10\n",
    "param_grid = {\n",
    "    \"poly_features__degree\": range(1, 11),\n",
    "}\n",
    "# grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv = 5, scoring = \"neg_root_mean_squared_error\")\n",
    "grid_search.fit(X, y)\n",
    "# score and best model\n",
    "best_degree = grid_search.best_params_[\"poly_features__degree\"]\n",
    "best_rmse = -grid_search.best_score_\n",
    "print(f\"Best Degree: {best_degree}\")\n",
>>>>>>> 4f861df75a8407e167855210ff45af54ad5f3431
    "print(f\"Best Cross-Validated RMSE: {best_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There can be overfitting and diminishing returns as well as computational costs. We can do a randomized search instead."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
