{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6: Variable Selection and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Different Model Specs\n",
    "### A. Regression without regularization\n",
    "1. Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, make_scorer, mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitters = pd.read_csv(r\"C:\\Users\\achur\\OneDrive\\Desktop\\School\\CP Fall 2024\\544\\Hitters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def regression_analysis(model_type, X, y, categorical_columns, interaction_columns, param_grid=None, cv=5):\n",
    "    \"\"\"\n",
    "    Performs regression analysis with linear, ridge, lasso, or elastic net regression using a pipeline.\n",
    "\n",
    "    Parameters:\n",
    "    - model_type: String specifying model ('linear', 'ridge', 'lasso', or 'elasticnet')\n",
    "    - X: DataFrame of predictors\n",
    "    - y: Series of target values\n",
    "    - categorical_columns: List of columns to dummify\n",
    "    - interaction_columns: List of columns to create interactions\n",
    "    - param_grid: Dictionary of hyperparameters for grid search (for ridge, lasso, or elastic net)\n",
    "    - cv: Number of cross-validation folds\n",
    "\n",
    "    Returns:\n",
    "    - Fitted model, cross-validated MSE, and DataFrame of coefficients (if applicable)\n",
    "    \"\"\"\n",
    "\n",
    "    # colummn transformer\n",
    "    ct_dummies = ColumnTransformer(\n",
    "        [(\"dummify\", OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_columns)],\n",
    "        remainder=\"passthrough\"\n",
    "    ).set_output(transform=\"pandas\")\n",
    "\n",
    "    ct_inter = ColumnTransformer(\n",
    "        [\n",
    "            (\"interaction\", PolynomialFeatures(interaction_only=True, include_bias=False), interaction_columns)\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    ).set_output(transform=\"pandas\")\n",
    "\n",
    "    # model type\n",
    "    if model_type == 'linear':\n",
    "        model = LinearRegression()\n",
    "    elif model_type == 'ridge':\n",
    "        model = Ridge()\n",
    "    elif model_type == 'lasso':\n",
    "        model = Lasso()\n",
    "    elif model_type == 'elasticnet':\n",
    "        model = ElasticNet()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model_type. Choose from 'linear', 'ridge', 'lasso', or 'elasticnet'.\")\n",
    "\n",
    "    # pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('dummification', ct_dummies),\n",
    "        ('interactions', ct_inter),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "\n",
    "    # pipeline and cross-validation for linear\n",
    "    if model_type == 'linear':\n",
    "        pipeline.fit(X, y)\n",
    "        mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "        cv_scores = cross_val_score(pipeline, X, y, cv=cv, scoring=mse_scorer)\n",
    "        average_mse = -np.mean(cv_scores)\n",
    "\n",
    "        # Extract coefficients if applicable\n",
    "        regressor = pipeline.named_steps['regressor']\n",
    "        coefficients = regressor.coef_\n",
    "        transformed_features = pipeline.named_steps['interactions'].get_feature_names_out()\n",
    "        coeff_df = pd.DataFrame({'Feature': transformed_features, 'Coefficient': coefficients})\n",
    "        coeff_df = coeff_df.sort_values(by='Coefficient', key=abs, ascending=False)\n",
    "\n",
    "        print(f'Linear Regression - Estimated MSE: {average_mse:.2f}')\n",
    "        print('Most important coefficients:')\n",
    "        print(coeff_df.head())\n",
    "        return pipeline, average_mse, coeff_df\n",
    "\n",
    "    # hyperparamter tuning for ridge, lasso, and elasticnet\n",
    "    if model_type in ['ridge', 'lasso', 'elasticnet']:\n",
    "        if not param_grid:\n",
    "            raise ValueError(\"param_grid must be provided for ridge, lasso, and elastic net regression.\")\n",
    "\n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X, y)\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        best_mse = -grid_search.best_score_\n",
    "\n",
    "        # coefficients\n",
    "        regressor = best_model.named_steps['regressor']\n",
    "        coefficients = regressor.coef_\n",
    "        transformed_features = best_model.named_steps['interactions'].get_feature_names_out()\n",
    "        coeff_df = pd.DataFrame({'Feature': transformed_features, 'Coefficient': coefficients})\n",
    "        coeff_df = coeff_df.sort_values(by='Coefficient', key=abs, ascending=False)\n",
    "\n",
    "        print(f'{model_type.capitalize()} Regression - Best Parameters: {best_params}')\n",
    "        print(f'Estimated MSE: {best_mse:.2f}')\n",
    "        print('Most important coefficients:')\n",
    "        print(coeff_df.head())\n",
    "\n",
    "        return best_model, best_mse, coeff_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fit this pipeline to the full dataset, and interpret a few of the most important coefficients.\n",
    "3. Use cross-validation to estimate the MSE you would expect if you used this pipeline to predict 1989 salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - Estimated MSE: 174559.50\n",
      "Most important coefficients:\n",
      "                                           Feature  Coefficient\n",
      "0                    interaction__remainder__Years   166.978056\n",
      "2  interaction__remainder__Years dummify__League_A    27.099368\n",
      "1                   interaction__dummify__League_A   -18.891896\n",
      "Linear Regression - Estimated MSE: 174559.50\n",
      "Most important coefficients:\n",
      "                                           Feature  Coefficient\n",
      "0                    interaction__remainder__Years   166.978056\n",
      "2  interaction__remainder__Years dummify__League_A    27.099368\n",
      "1                   interaction__dummify__League_A   -18.891896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(steps=[('dummification',\n",
       "                  ColumnTransformer(remainder='passthrough',\n",
       "                                    transformers=[('dummify',\n",
       "                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                 sparse_output=False),\n",
       "                                                   ['League'])])),\n",
       "                 ('interactions',\n",
       "                  ColumnTransformer(transformers=[('interaction',\n",
       "                                                   PolynomialFeatures(include_bias=False,\n",
       "                                                                      interaction_only=True),\n",
       "                                                   ['remainder__Years',\n",
       "                                                    'dummify__League_A'])])),\n",
       "                 ('scaler', StandardScaler()),\n",
       "                 ('regressor', LinearRegression())]),\n",
       " 174559.4960037865,\n",
       "                                            Feature  Coefficient\n",
       " 0                    interaction__remainder__Years   166.978056\n",
       " 2  interaction__remainder__Years dummify__League_A    27.099368\n",
       " 1                   interaction__dummify__League_A   -18.891896)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = hitters.drop(columns=['Salary'])\n",
    "y = hitters['Salary'].dropna()\n",
    "X = X.loc[y.index]\n",
    "\n",
    "categorical_columns = ['League']\n",
    "interaction_columns = [\"remainder__Years\", \"dummify__League_A\"]\n",
    "\n",
    "# use function for linear regression\n",
    "regression_analysis('linear', X, y, categorical_columns, interaction_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation: The first feature represents the linear relationship between Years and Salary. This means that on average, for each additional year of playing, the predicted Salary increases by 166.978k, holding all other variables constant. The second feature represnts the linear relationship between the interaction terms Year and League A. This means that for players in League A, each additional year of playing, the salary is expected to increase by 27.099k. The third feature represents the relationship between League A and the other league. This means that being in League A is associated with a -18.89k decrease in salary compared to the other league"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Ridge regression\n",
    "1. Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary ridge regression.\n",
    "2. Use cross-validation to tune the lambda hyperparameter.\n",
    "3. Fit the pipeline with your chosen lambda to the full dataset, and interpret a few of the most important coefficients.\n",
    "4. Report the MSE you would expect if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression - Best Parameters: {'regressor__alpha': 10.0}\n",
      "Estimated MSE: 174434.04\n",
      "Most important coefficients:\n",
      "                                           Feature  Coefficient\n",
      "0                    interaction__remainder__Years   158.320468\n",
      "2  interaction__remainder__Years dummify__League_A    32.363761\n",
      "1                   interaction__dummify__League_A   -21.636648\n",
      "Ridge Regression - Best Parameters: {'regressor__alpha': 10.0}\n",
      "Estimated MSE: 174434.04\n",
      "Most important coefficients:\n",
      "                                           Feature  Coefficient\n",
      "0                    interaction__remainder__Years   158.320468\n",
      "2  interaction__remainder__Years dummify__League_A    32.363761\n",
      "1                   interaction__dummify__League_A   -21.636648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(steps=[('dummification',\n",
       "                  ColumnTransformer(remainder='passthrough',\n",
       "                                    transformers=[('dummify',\n",
       "                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                 sparse_output=False),\n",
       "                                                   ['League'])])),\n",
       "                 ('interactions',\n",
       "                  ColumnTransformer(transformers=[('interaction',\n",
       "                                                   PolynomialFeatures(include_bias=False,\n",
       "                                                                      interaction_only=True),\n",
       "                                                   ['remainder__Years',\n",
       "                                                    'dummify__League_A'])])),\n",
       "                 ('scaler', StandardScaler()),\n",
       "                 ('regressor', Ridge(alpha=10.0))]),\n",
       " 174434.03772695793,\n",
       "                                            Feature  Coefficient\n",
       " 0                    interaction__remainder__Years   158.320468\n",
       " 2  interaction__remainder__Years dummify__League_A    32.363761\n",
       " 1                   interaction__dummify__League_A   -21.636648)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use function for ridge with hyper parameter\n",
    "param_grid_ridge = {'regressor__alpha': [0.1, 1.0, 10.0, 100.0]}\n",
    "regression_analysis('ridge', X, y, categorical_columns, interaction_columns, param_grid=param_grid_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Lasso Regression\n",
    "1. Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary ridge regression.\n",
    "2. Use cross-validation to tune the lambda hyperparameter.\n",
    "3. Fit the pipeline with your chosen lambda to the full dataset, and interpret a few of the most important coefficients.\n",
    "4. Report the MSE you would expect if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression - Best Parameters: {'regressor__alpha': 10.0}\n",
      "Estimated MSE: 173695.16\n",
      "Most important coefficients:\n",
      "                                           Feature  Coefficient\n",
      "0                    interaction__remainder__Years   169.341332\n",
      "2  interaction__remainder__Years dummify__League_A     2.050551\n",
      "1                   interaction__dummify__League_A    -0.000000\n",
      "Lasso Regression - Best Parameters: {'regressor__alpha': 10.0}\n",
      "Estimated MSE: 173695.16\n",
      "Most important coefficients:\n",
      "                                           Feature  Coefficient\n",
      "0                    interaction__remainder__Years   169.341332\n",
      "2  interaction__remainder__Years dummify__League_A     2.050551\n",
      "1                   interaction__dummify__League_A    -0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(steps=[('dummification',\n",
       "                  ColumnTransformer(remainder='passthrough',\n",
       "                                    transformers=[('dummify',\n",
       "                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                 sparse_output=False),\n",
       "                                                   ['League'])])),\n",
       "                 ('interactions',\n",
       "                  ColumnTransformer(transformers=[('interaction',\n",
       "                                                   PolynomialFeatures(include_bias=False,\n",
       "                                                                      interaction_only=True),\n",
       "                                                   ['remainder__Years',\n",
       "                                                    'dummify__League_A'])])),\n",
       "                 ('scaler', StandardScaler()),\n",
       "                 ('regressor', Lasso(alpha=10.0))]),\n",
       " 173695.16435016156,\n",
       "                                            Feature  Coefficient\n",
       " 0                    interaction__remainder__Years   169.341332\n",
       " 2  interaction__remainder__Years dummify__League_A     2.050551\n",
       " 1                   interaction__dummify__League_A    -0.000000)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use function for lasso with hyperparameter\n",
    "param_grid_lasso = {'regressor__alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "regression_analysis('lasso', X, y, categorical_columns, interaction_columns, param_grid=param_grid_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Elastic Net\n",
    "1. Create a pipeline that includes all the columns as predictors for Salary, and performs ordinary ridge regression.\n",
    "2. Use cross-validation to tune the lambda and alpha hyperparameters.\n",
    "3. Fit the pipeline with your chosen hyperparameters to the full dataset, and interpret a few of the most important coefficients.\n",
    "4. Report the MSE you would expect if you used this pipeline to predict 1989 salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet Regression - Best Parameters: {'regressor__alpha': 0.1, 'regressor__l1_ratio': 0.5}\n",
      "Estimated MSE: 174433.42\n",
      "Most important coefficients:\n",
      "                                           Feature  Coefficient\n",
      "0                    interaction__remainder__Years   156.039981\n",
      "2  interaction__remainder__Years dummify__League_A    33.245256\n",
      "1                   interaction__dummify__League_A   -21.884569\n",
      "Elasticnet Regression - Best Parameters: {'regressor__alpha': 0.1, 'regressor__l1_ratio': 0.5}\n",
      "Estimated MSE: 174433.42\n",
      "Most important coefficients:\n",
      "                                           Feature  Coefficient\n",
      "0                    interaction__remainder__Years   156.039981\n",
      "2  interaction__remainder__Years dummify__League_A    33.245256\n",
      "1                   interaction__dummify__League_A   -21.884569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(steps=[('dummification',\n",
       "                  ColumnTransformer(remainder='passthrough',\n",
       "                                    transformers=[('dummify',\n",
       "                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                 sparse_output=False),\n",
       "                                                   ['League'])])),\n",
       "                 ('interactions',\n",
       "                  ColumnTransformer(transformers=[('interaction',\n",
       "                                                   PolynomialFeatures(include_bias=False,\n",
       "                                                                      interaction_only=True),\n",
       "                                                   ['remainder__Years',\n",
       "                                                    'dummify__League_A'])])),\n",
       "                 ('scaler', StandardScaler()),\n",
       "                 ('regressor', ElasticNet(alpha=0.1))]),\n",
       " 174433.42238269112,\n",
       "                                            Feature  Coefficient\n",
       " 0                    interaction__remainder__Years   156.039981\n",
       " 2  interaction__remainder__Years dummify__League_A    33.245256\n",
       " 1                   interaction__dummify__League_A   -21.884569)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use function for elasticnet with hyperparameter\n",
    "param_grid_elasticnet = {'regressor__alpha': [0.01, 0.1, 1.0, 10.0], 'regressor__l1_ratio': [0.2, 0.5, 0.8]}\n",
    "regression_analysis('elasticnet', X, y, categorical_columns, interaction_columns, param_grid=param_grid_elasticnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II. Variable Selection\n",
    "Based on the above results, decide on:\n",
    "\n",
    "* Which numeric variable is most important.\n",
    "\n",
    "* Which five numeric variables are most important\n",
    "\n",
    "* Which categorical variable is most important\n",
    "\n",
    "For each of the four model specifications, compare the following possible feature sets:\n",
    "\n",
    "1. Using only the one best numeric variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using only the five best variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using the five best numeric variables and their interactions with the one best categorical variable.\n",
    "\n",
    "Report which combination of features and model performed best, based on the validation metric of MSE. (Note: lambda and alpha must be re-tuned for each feature set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III. Discussion\n",
    "\n",
    "### A. Ridge\n",
    "\n",
    "Compare your Ridge models with your ordinary regression models. How did your coefficients compare? Why does this make sense?\n",
    "\n",
    "### B. Lasso\n",
    "\n",
    "Compare your LASSO model in I with your three LASSO models in II. Did you get the same lambda results? Why does this make sense? Did you get the same MSEs? Why does this make sense?\n",
    "\n",
    "### C. Elastic Net\n",
    "\n",
    "Compare your MSEs for the Elastic Net models with those for the Ridge and LASSO models. Why does it make sense that Elastic Net always “wins”?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV: Final Model\n",
    "\n",
    "Fit your final best pipeline on the full dataset, and summarize your results in a few short sentences and a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix and References"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
