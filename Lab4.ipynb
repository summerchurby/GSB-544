{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Lab 4\n",
    "author: Summer Churby\n",
    "format: \n",
    "        html: \n",
    "            toc: true\n",
    "            code-fold: true\n",
    "embed-resources: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the Location Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use the beautifulsoup library to scrape the data (from the link above) on state names and corresponding number of store locations, for the following chains:\n",
    "* Starbucks\n",
    "\n",
    "* Dunkin’ Donuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starbucks\n",
    "response = requests.get(\"https://worldpopulationreview.com/state-rankings/starbucks-stores-by-state\")\n",
    "starbucks_soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "starbucks_tables = starbucks_soup.find_all(\"table\", class_ = \"wpr-table\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            State  Year Starbucks Stores    Company\n",
      "0      California  2023            3,080  Starbucks\n",
      "1      California  2021            2,959  Starbucks\n",
      "2      California  2024            3,117  Starbucks\n",
      "3           Texas  2023            1,346  Starbucks\n",
      "4           Texas  2021            1,215  Starbucks\n",
      "..            ...   ...              ...        ...\n",
      "148  North Dakota  2021               20  Starbucks\n",
      "149  North Dakota  2024                   Starbucks\n",
      "150       Vermont  2023                8  Starbucks\n",
      "151       Vermont  2021               35  Starbucks\n",
      "152       Vermont  2024                   Starbucks\n",
      "\n",
      "[153 rows x 4 columns]\n",
      "            State  Year Starbucks Stores    Company\n",
      "0      California  2023            3,080  Starbucks\n",
      "1      California  2021            2,959  Starbucks\n",
      "2      California  2024            3,117  Starbucks\n",
      "3           Texas  2023            1,346  Starbucks\n",
      "4           Texas  2021            1,215  Starbucks\n",
      "..            ...   ...              ...        ...\n",
      "148  North Dakota  2021               20  Starbucks\n",
      "149  North Dakota  2024                   Starbucks\n",
      "150       Vermont  2023                8  Starbucks\n",
      "151       Vermont  2021               35  Starbucks\n",
      "152       Vermont  2024                   Starbucks\n",
      "\n",
      "[153 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# create empty lists for the dictionaries\n",
    "starbucks_rows = []\n",
    "states_list = []\n",
    "\n",
    "for th in starbucks_tables.find_all(\"th\")[4:]:\n",
    "    states = th.get_text(strip = True)\n",
    "    states_list.append(states)\n",
    "\n",
    "for i, tr in enumerate(starbucks_tables.find_all(\"tr\")[1:]):\n",
    "    state = states_list[i]\n",
    "\n",
    "    cells = tr.find_all(\"td\")\n",
    "    \n",
    "    # extract cells for stores in 2023, 2021, and 2024\n",
    "    stores2023 = cells[0].get_text(strip=True)\n",
    "    stores2021 = cells[1].get_text(strip=True)\n",
    "    stores2024 = cells[2].get_text(strip=True)\n",
    "\n",
    "    # append the rows with the dictionaries\n",
    "    starbucks_rows.append({\n",
    "        \"State\": state,\n",
    "        \"Year\": 2023,\n",
    "        \"Starbucks Stores\": stores2023, \n",
    "        \"Company\": \"Starbucks\"\n",
    "    })\n",
    "    starbucks_rows.append({\n",
    "        \"State\": state,\n",
    "        \"Year\": 2021,\n",
    "        \"Starbucks Stores\": stores2021,\n",
    "        \"Company\": \"Starbucks\"\n",
    "    })\n",
    "    starbucks_rows.append({\n",
    "        \"State\": state,\n",
    "        \"Year\": 2024,\n",
    "        \"Starbucks Stores\": stores2024, \n",
    "        \"Company\": \"Starbucks\"\n",
    "    })\n",
    "\n",
    "# convert into a data frame\n",
    "df = pd.DataFrame(starbucks_rows)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dunkin\n",
    "dunkin_response = requests.get(\"https://worldpopulationreview.com/state-rankings/dunkin-donuts-by-state\")\n",
    "dunkin_soup = BeautifulSoup(dunkin_response.content, \"html.parser\")\n",
    "dunkin_table = dunkin_soup.find(\"table\", class_ = \"wpr-table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             State  Year Dunkin Stores Company\n",
      "0         New York  2024         1,431  Dunkin\n",
      "1         New York  2023         1,414  Dunkin\n",
      "2    Massachusetts  2024         1,042  Dunkin\n",
      "3    Massachusetts  2023         1,068  Dunkin\n",
      "4          Florida  2024           909  Dunkin\n",
      "..             ...   ...           ...     ...\n",
      "97          Oregon  2023             0  Dunkin\n",
      "98    South Dakota  2024             0  Dunkin\n",
      "99    South Dakota  2023             0  Dunkin\n",
      "100     Washington  2024             0  Dunkin\n",
      "101     Washington  2023            19  Dunkin\n",
      "\n",
      "[102 rows x 4 columns]\n",
      "             State  Year Dunkin Stores Company\n",
      "0         New York  2024         1,431  Dunkin\n",
      "1         New York  2023         1,414  Dunkin\n",
      "2    Massachusetts  2024         1,042  Dunkin\n",
      "3    Massachusetts  2023         1,068  Dunkin\n",
      "4          Florida  2024           909  Dunkin\n",
      "..             ...   ...           ...     ...\n",
      "97          Oregon  2023             0  Dunkin\n",
      "98    South Dakota  2024             0  Dunkin\n",
      "99    South Dakota  2023             0  Dunkin\n",
      "100     Washington  2024             0  Dunkin\n",
      "101     Washington  2023            19  Dunkin\n",
      "\n",
      "[102 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# create empty lists for the dictionaries\n",
    "dunkin_rows = []\n",
    "states_list = []\n",
    "\n",
    "for th in dunkin_table.find_all(\"th\")[3:]:\n",
    "    states = th.get_text(strip = True)\n",
    "    states_list.append(states)\n",
    "\n",
    "for i, tr in enumerate(dunkin_table.find_all(\"tr\")[1:]):\n",
    "    state = states_list[i]\n",
    "\n",
    "    cells = tr.find_all(\"td\")\n",
    "\n",
    "    # extract cells for stores\n",
    "    dunkin_stores2024 = cells[0].get_text(strip=True)\n",
    "    dunkin_stores2023 = cells[1].get_text(strip=True)\n",
    "\n",
    "    #append the rows with the dictionaries\n",
    "    dunkin_rows.append({\n",
    "        \"State\": state,\n",
    "        \"Year\": 2024,\n",
    "        \"Dunkin Stores\": dunkin_stores2024,\n",
    "        \"Company\": \"Dunkin\"\n",
    "    })\n",
    "    dunkin_rows.append({\n",
    "        \"State\": state,\n",
    "        \"Year\": 2023,\n",
    "        \"Dunkin Stores\": dunkin_stores2023,\n",
    "        \"Company\": \"Dunkin\"\n",
    "    })\n",
    "# convert to data frame\n",
    "df = pd.DataFrame(dunkin_rows)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Parse, merge and tidy your data. Think carefully about what the tidy version of this dataset is with multiple years represented on the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       State  Year Dunkin Stores    Company Starbucks Stores\n",
      "0    Alabama  2021           NaN  Starbucks               99\n",
      "1    Alabama  2023            59     Dunkin              NaN\n",
      "2    Alabama  2023           NaN  Starbucks               85\n",
      "3    Alabama  2024            69     Dunkin              NaN\n",
      "4    Alabama  2024           NaN  Starbucks                 \n",
      "..       ...   ...           ...        ...              ...\n",
      "250  Wyoming  2021           NaN  Starbucks               26\n",
      "251  Wyoming  2023             1     Dunkin              NaN\n",
      "252  Wyoming  2023           NaN  Starbucks               23\n",
      "253  Wyoming  2024             1     Dunkin              NaN\n",
      "254  Wyoming  2024           NaN  Starbucks                 \n",
      "\n",
      "[255 rows x 5 columns]\n",
      "       State  Year Dunkin Stores    Company Starbucks Stores\n",
      "0    Alabama  2021           NaN  Starbucks               99\n",
      "1    Alabama  2023            59     Dunkin              NaN\n",
      "2    Alabama  2023           NaN  Starbucks               85\n",
      "3    Alabama  2024            69     Dunkin              NaN\n",
      "4    Alabama  2024           NaN  Starbucks                 \n",
      "..       ...   ...           ...        ...              ...\n",
      "250  Wyoming  2021           NaN  Starbucks               26\n",
      "251  Wyoming  2023             1     Dunkin              NaN\n",
      "252  Wyoming  2023           NaN  Starbucks               23\n",
      "253  Wyoming  2024             1     Dunkin              NaN\n",
      "254  Wyoming  2024           NaN  Starbucks                 \n",
      "\n",
      "[255 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# rename the dataframes\n",
    "df_dunkin = pd.DataFrame(dunkin_rows)\n",
    "df_starbucks = pd.DataFrame(starbucks_rows)\n",
    "\n",
    "#merge two data frames\n",
    "coffee = pd.merge(df_dunkin, df_starbucks, on=[\"State\", \"Year\", \"Company\"], how=\"outer\")\n",
    "print(coffee)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplemental Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Scrape the state names and populations from this wikipedia page. Merge these data with your coffee dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       State    Year Dunkin Stores    Company Starbucks Stores Population\n",
      "0    Alabama  2021.0           NaN  Starbucks               99  5,024,279\n",
      "1    Alabama  2023.0            59     Dunkin              NaN  5,024,279\n",
      "2    Alabama  2023.0           NaN  Starbucks               85  5,024,279\n",
      "3    Alabama  2024.0            69     Dunkin              NaN  5,024,279\n",
      "4    Alabama  2024.0           NaN  Starbucks                   5,024,279\n",
      "..       ...     ...           ...        ...              ...        ...\n",
      "259  Wyoming  2021.0           NaN  Starbucks               26    576,851\n",
      "260  Wyoming  2023.0             1     Dunkin              NaN    576,851\n",
      "261  Wyoming  2023.0           NaN  Starbucks               23    576,851\n",
      "262  Wyoming  2024.0             1     Dunkin              NaN    576,851\n",
      "263  Wyoming  2024.0           NaN  Starbucks                     576,851\n",
      "\n",
      "[264 rows x 6 columns]\n",
      "       State    Year Dunkin Stores    Company Starbucks Stores Population\n",
      "0    Alabama  2021.0           NaN  Starbucks               99  5,024,279\n",
      "1    Alabama  2023.0            59     Dunkin              NaN  5,024,279\n",
      "2    Alabama  2023.0           NaN  Starbucks               85  5,024,279\n",
      "3    Alabama  2024.0            69     Dunkin              NaN  5,024,279\n",
      "4    Alabama  2024.0           NaN  Starbucks                   5,024,279\n",
      "..       ...     ...           ...        ...              ...        ...\n",
      "259  Wyoming  2021.0           NaN  Starbucks               26    576,851\n",
      "260  Wyoming  2023.0             1     Dunkin              NaN    576,851\n",
      "261  Wyoming  2023.0           NaN  Starbucks               23    576,851\n",
      "262  Wyoming  2024.0             1     Dunkin              NaN    576,851\n",
      "263  Wyoming  2024.0           NaN  Starbucks                     576,851\n",
      "\n",
      "[264 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "pop_response = requests.get(\"https://simple.wikipedia.org/wiki/List_of_U.S._states_by_population\")\n",
    "pop_soup = BeautifulSoup(pop_response.content, \"html.parser\")\n",
    "pop_table = pop_soup.find(\"table\", class_ = \"wikitable\")\n",
    "\n",
    "pop_rows = []\n",
    "\n",
    "for tr in pop_table.find_all(\"tr\")[1:]:\n",
    "    cells = tr.find_all('td')\n",
    "    if len(cells) >= 3:\n",
    "        state = cells[2].get_text(strip = True)\n",
    "        population = cells[3].get_text(strip = True)\n",
    "\n",
    "\n",
    "        pop_rows.append({\n",
    "        \"State\": state,\n",
    "        \"Population\": population})\n",
    "\n",
    "# convert to data frame\n",
    "pop_df = pd.DataFrame(pop_rows)\n",
    "\n",
    "# merge two data frames\n",
    "coffee_new = pd.merge(coffee, pop_df, on=\"State\", how = \"outer\")\n",
    "print(coffee_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Find the revenue, stock price, or your financial metric of choice for each of the companies listed above (if you can find a website to scrape these from that’s great!…but it’s okay if you manually enter these). Merge these values into your big dataset. Note: these values may be repeated for each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       State    Year Dunkin Stores  ... Starbucks Stores Population Stock Price\n",
      "0    Alabama  2023.0            59  ...              NaN  5,024,279      106.48\n",
      "1    Alabama  2024.0           NaN  ...                   5,024,279       97.31\n",
      "2    Alabama  2023.0           NaN  ...               85  5,024,279       97.31\n",
      "3    Alabama  2021.0           NaN  ...               99  5,024,279       97.31\n",
      "4    Alabama  2024.0            69  ...              NaN  5,024,279      106.48\n",
      "..       ...     ...           ...  ...              ...        ...         ...\n",
      "259  Wyoming  2021.0           NaN  ...               26    576,851       97.31\n",
      "260  Wyoming  2023.0           NaN  ...               23    576,851       97.31\n",
      "261  Wyoming  2024.0           NaN  ...                     576,851       97.31\n",
      "262  Wyoming  2023.0             1  ...              NaN    576,851      106.48\n",
      "263  Wyoming  2024.0             1  ...              NaN    576,851      106.48\n",
      "\n",
      "[264 rows x 7 columns]\n",
      "       State    Year Dunkin Stores  ... Starbucks Stores Population Stock Price\n",
      "0    Alabama  2023.0            59  ...              NaN  5,024,279      106.48\n",
      "1    Alabama  2024.0           NaN  ...                   5,024,279       97.31\n",
      "2    Alabama  2023.0           NaN  ...               85  5,024,279       97.31\n",
      "3    Alabama  2021.0           NaN  ...               99  5,024,279       97.31\n",
      "4    Alabama  2024.0            69  ...              NaN  5,024,279      106.48\n",
      "..       ...     ...           ...  ...              ...        ...         ...\n",
      "259  Wyoming  2021.0           NaN  ...               26    576,851       97.31\n",
      "260  Wyoming  2023.0           NaN  ...               23    576,851       97.31\n",
      "261  Wyoming  2024.0           NaN  ...                     576,851       97.31\n",
      "262  Wyoming  2023.0             1  ...              NaN    576,851      106.48\n",
      "263  Wyoming  2024.0             1  ...              NaN    576,851      106.48\n",
      "\n",
      "[264 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# stock prices\n",
    "# 97.31 for starbucks\n",
    "# 106.48 for dunkin \n",
    "financial_data = {\n",
    "    \"Company\": [\"Starbucks\", \"Dunkin\"],\n",
    "    \"Stock Price\": [97.31, 106.48]\n",
    "}\n",
    "\n",
    "financial_df = pd.DataFrame(financial_data)\n",
    "\n",
    "financial_coffee = pd.merge(coffee_new, financial_df, on = \"Company\", how = \"outer\")\n",
    "financial_coffee = financial_coffee.sort_values(by = \"State\").reset_index(drop=True)\n",
    "print(financial_coffee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create a region variable in your dataset according to the scheme on this wikipedia page: Northeast, Midwest, South, West. You do not need to scrape this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regions for us\n",
    "regions = {\n",
    "    \"Conneticut\": \"Northeast\",\n",
    "    \"Maine\": \"Northeast\",\n",
    "    \"Massachusetts\": \"Northeast\",\n",
    "    \"New Hampshire\": \"Northeast\",\n",
    "    \"Rhode Island\": \"Northeast\",\n",
    "    \"Vermont\": \"Northeast\",\n",
    "    \"New Jersey\": \"Northeast\",\n",
    "    \"New York\": \"Northeast\",\n",
    "    \"Pennsylvania\": \"Northeast\",\n",
    "    \"Illinois\": \"Midwest\",\n",
    "    \"Indiana\": \"Midwest\",\n",
    "    \"Michigan\": \"Midwest\",\n",
    "    \"Ohio\": \"Midwest\",\n",
    "    \"Wisconsin\": \"Midwest\",\n",
    "    \"Iowa\": \"Midwest\",\n",
    "    \"Kansas\": \"Midwest\",\n",
    "    \"Minnesota\": \"Midwest\",\n",
    "    \"Missouri\": \"Midwest\",\n",
    "    \"Nebraska\": \"Midwest\",\n",
    "    \"North Dakota\": \"Midwest\",\n",
    "    \"South Dakota\": \"Midwest\",\n",
    "    \"Delaware\": \"South\",\n",
    "    \"Florida\": \"South\",\n",
    "    \"Georgia\": \"South\",\n",
    "    \"Maryland\": \"South\",\n",
    "    \"North Carolina\": \"South\",\n",
    "    \"South Carolina\": \"South\",\n",
    "    \"Virginia\": \"South\",\n",
    "    \"District of Columbia\": \"South\",\n",
    "    \"West Virginia\": \"South\",\n",
    "    \"Alabama\": \"South\",\n",
    "    \"Kentucky\": \"South\",\n",
    "    \"Mississippi\": \"South\",\n",
    "    \"Tennessee\": \"South\",\n",
    "    \"Arkansas\": \"South\",\n",
    "    \"Louisiana\": \"South\",\n",
    "    \"Oklahoma\": \"South\",\n",
    "    \"Texas\": \"South\",\n",
    "    \"Arizona\": \"West\",\n",
    "    \"Colorado\": \"West\",\n",
    "    \"Idaho\": \"West\",\n",
    "    \"Montana\": \"West\", \n",
    "    \"Nevada\": \"West\", \n",
    "    \"New Mexico\": \"West\",\n",
    "    \"Utah\": \"West\",\n",
    "    \"Wyoming\": \"West\",\n",
    "    \"Alaska\": \"West\",\n",
    "    \"California\": \"West\",\n",
    "    \"Hawaii\": \"West\",\n",
    "    \"Oregon\": \"West\",\n",
    "    \"Washington\": \"West\"\n",
    "}\n",
    "\n",
    "financial_coffee[\"Regions\"] = financial_coffee[\"State\"].map(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_coffee[\"Starbucks Stores\"] = pd.to_numeric(financial_coffee[\"Starbucks Stores\"], errors='coerce')\n",
    "financial_coffee[\"Dunkin Stores\"] = pd.to_numeric(financial_coffee[\"Dunkin Stores\"], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Assess and comment on the prevalence of each chain. Some questions to consider (you don’t need to answer all of these and you may come up with your own):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the dataframe, we cannot fully compare the two chains becasue the Starbucks data includes information on years 2021, 2023, and 2024. Dunkin contains information on years 2023 and 2024. A conclusion could be drawn that population is somewhat correlated witht the number of Starbucks Stores. For example, Florida has the highest number of Starbucks stores at 892 stores for 2024 with a population of 21 million, while Vermont has the lowest amount of stores with 8 for 2023 with a population of 643k. The same conclusion could be drawn for Dunkin Stores with Florida having the highest number of stores at 909 with a population of 21 million, while Wyoming has 1 store with a population of 576k. Dunkin is more popular in the South and Northeast regions with there being a higher number of stores in those regions than the others. Starbucks is more popular in the West and South regions with there being a higher number of stores in those regions than others. The financial data does not change from state to state or region to region because it is the current stock price for each company and is universal across the country. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert your code for Exercises 1-3 above to a function that takes a single argument: the URL. This function should\n",
    "\n",
    "* Scrape the information on state names and corresponding number of store locations on the webpage specified (assume the page has a table in the same form and placement as the ones you scraped above)\n",
    "\n",
    "* Extract the name of the company from either the URL specified or the webpage (assume the URL will have the same format as the ones used above)\n",
    "\n",
    "* Return a clean, organized and tidy dataset. Find a page other than Starbucks and Dunkin’ Donuts to test this on to confirm that it works. It’s fine if this is not related to coffee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def scrape_store_data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    company_name = re.search(r'state-rankings/(.*?)-by-state', url).group(1).replace('-', ' ').title()\n",
    "    table = soup.find('table', class_ = 'wpr-table')\n",
    "    states_list = [th.get_text(strip = True) for th in table.find_all('th')[3:]]\n",
    "    rows = []\n",
    "    for i, tr in enumerate(table.find_all('tr')[1:]):\n",
    "        #state = states_list[i]\n",
    "        cells = tr.find_all('td')\n",
    "        if i < len(states_list):\n",
    "            state = states_list[i]\n",
    "        else: \n",
    "            continue\n",
    "\n",
    "        stores_2023 = cells[0].get_text(strip = True)\n",
    "        stores_2021 = cells[1].get_text(strip = True) if len(cells) > 1 else None\n",
    "        stores_2024 = cells[2].get_text(strip = True) if len(cells) > 2 else None\n",
    "\n",
    "        if stores_2023:\n",
    "            rows.append({\"State\": state, \"Year\": 2023, \"Stores\": stores_2023, \"Company\": company_name})\n",
    "        if stores_2021:\n",
    "            rows.append({\"State\": state, \"Year\": 2021, \"Stores\": stores_2021, \"Company\": company_name})\n",
    "        if stores_2024:\n",
    "            rows.append({\"State\": state, \"Year\": 2024, \"Stores\": stores_2024, \"Company\": company_name})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"Stores\"] = pd.to_numeric(df[\"Stores\"], errors='coerce')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_store_data2(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    company_name = re.search(r'state-rankings/(.*?)-by-state', url).group(1).replace('-', ' ').title()\n",
    "    table = soup.find('table', class_ = 'wpr-table')\n",
    "    states_list = [th.get_text(strip = True) for th in table.find_all('th')[3:]]\n",
    "    headers = []\n",
    "    rows = []\n",
    "    states_list = []\n",
    "    for th in table.find_all('th', class_ = 'datatable-th'):\n",
    "        header = th.get_text(strip = True)\n",
    "        headers.append(header)\n",
    "    index = len(table.find_all('th', class_ = \"datatable-th\")) \n",
    "    \n",
    "    for th in table.find_all('th')[index:]:\n",
    "        states = th.get_text(strip = True)\n",
    "        states_list.append(states)\n",
    "\n",
    "        stores_2023 = cells[0].get_text(strip = True)\n",
    "        stores_2021 = cells[1].get_text(strip = True) if len(cells) > 1 else None\n",
    "        stores_2024 = cells[2].get_text(strip = True) if len(cells) > 2 else None\n",
    "\n",
    "        if stores_2023:\n",
    "            rows.append({\"State\": state, \"Year\": 2023, \"Stores\": stores_2023, \"Company\": company_name})\n",
    "        if stores_2021:\n",
    "            rows.append({\"State\": state, \"Year\": 2021, \"Stores\": stores_2021, \"Company\": company_name})\n",
    "        if stores_2024:\n",
    "            rows.append({\"State\": state, \"Year\": 2024, \"Stores\": stores_2024, \"Company\": company_name})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"Stores\"] = pd.to_numeric(df[\"Stores\"], errors='coerce')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Stores</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total U.S. (including D.C. and territories)</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chick Fil A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Total U.S. (including D.C. and territories)</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chick Fil A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total U.S. (including D.C. and territories)</td>\n",
       "      <td>2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chick Fil A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Total U.S. (including D.C. and territories)</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chick Fil A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Total U.S. (including D.C. and territories)</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chick Fil A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Total U.S. (including D.C. and territories)</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chick Fil A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Total U.S. (including D.C. and territories)</td>\n",
       "      <td>2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chick Fil A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Total U.S. (including D.C. and territories)</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chick Fil A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Total U.S. (including D.C. and territories)</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chick Fil A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Total U.S. (including D.C. and territories)</td>\n",
       "      <td>2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chick Fil A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           State  Year  Stores      Company\n",
       "0    Total U.S. (including D.C. and territories)  2023     NaN  Chick Fil A\n",
       "1    Total U.S. (including D.C. and territories)  2021     NaN  Chick Fil A\n",
       "2    Total U.S. (including D.C. and territories)  2024     NaN  Chick Fil A\n",
       "3    Total U.S. (including D.C. and territories)  2023     NaN  Chick Fil A\n",
       "4    Total U.S. (including D.C. and territories)  2021     NaN  Chick Fil A\n",
       "..                                           ...   ...     ...          ...\n",
       "148  Total U.S. (including D.C. and territories)  2021     NaN  Chick Fil A\n",
       "149  Total U.S. (including D.C. and territories)  2024     NaN  Chick Fil A\n",
       "150  Total U.S. (including D.C. and territories)  2023     NaN  Chick Fil A\n",
       "151  Total U.S. (including D.C. and territories)  2021     NaN  Chick Fil A\n",
       "152  Total U.S. (including D.C. and territories)  2024     NaN  Chick Fil A\n",
       "\n",
       "[153 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test function\n",
    "url = \"https://worldpopulationreview.com/state-rankings/chick-fil-a-by-state\"\n",
    "scrape_store_data2(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Stores</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Starbucks Stores 2024</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Starbucks Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Starbucks Stores 2024</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Starbucks Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Starbucks Stores 2024</td>\n",
       "      <td>2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Starbucks Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>California</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Starbucks Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Starbucks Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>2021</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Starbucks Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2023</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Starbucks Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2021</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Starbucks Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>2023</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Starbucks Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>2021</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Starbucks Stores</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     State  Year  Stores           Company\n",
       "0    Starbucks Stores 2024  2023     NaN  Starbucks Stores\n",
       "1    Starbucks Stores 2024  2021     NaN  Starbucks Stores\n",
       "2    Starbucks Stores 2024  2024     NaN  Starbucks Stores\n",
       "3               California  2023     NaN  Starbucks Stores\n",
       "4               California  2021     NaN  Starbucks Stores\n",
       "..                     ...   ...     ...               ...\n",
       "106          West Virginia  2021    26.0  Starbucks Stores\n",
       "107                Wyoming  2023    13.0  Starbucks Stores\n",
       "108                Wyoming  2021    20.0  Starbucks Stores\n",
       "109           North Dakota  2023     8.0  Starbucks Stores\n",
       "110           North Dakota  2021    35.0  Starbucks Stores\n",
       "\n",
       "[111 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test function\n",
    "url = \"https://worldpopulationreview.com/state-rankings/starbucks-stores-by-state\"\n",
    "scrape_store_data(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix and References\n",
    "\n",
    "https://worldpopulationreview.com/state-rankings/starbucks-stores-by-state\n",
    "\n",
    "https://worldpopulationreview.com/state-rankings/dunkin-donuts-by-state\n",
    "\n",
    "https://simple.wikipedia.org/wiki/List_of_U.S._states_by_population\n",
    "\n",
    "https://worldpopulationreview.com/state-rankings/chick-fil-a-by-state\n",
    "\n",
    "https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States \n",
    "\n",
    "https://finance.yahoo.com/quote/SBUX/\n",
    "\n",
    "https://www.investing.com/equities/dunkin-brands-group\n",
    "\n",
    "\n",
    "Generative A.I. Statement: Chat-GPT was used to suggest changes in code to debug errors. An example of errors include, incorrect syntax, incorrect usage of parameters for plots, making suggestions to fix parameters to resolve the error in code. Chat-GPT was only used to resolve errors in already hand written code. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
